# -*- coding: utf-8 -*-
"""
Created on Tue Apr 14 13:22:18 2020

@author: mshandhi3
"""



import numpy as np
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
from sklearn.datasets import load_digits
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
from sklearn.decomposition import PCA, NMF
from sklearn.feature_selection import SelectKBest,chi2, f_classif,  mutual_info_classif, RFE, SelectFromModel,SelectFdr
from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler

print(__doc__)

pipe = Pipeline([
    # the reduce_dim stage is populated by the param_grid
    ('reduce_dim', 'passthrough'),
    ('classify', SVC(kernel='rbf', gamma='auto', max_iter=10000))
])

N_FEATURES_OPTIONS = [50, 100, 150, 200]
C_OPTIONS = [1, 10, 100, 1000]
param_grid = [
    {
        'reduce_dim': [PCA(iterated_power=7), NMF()],
        'reduce_dim__n_components': N_FEATURES_OPTIONS,
        'classify__C': C_OPTIONS
    },
    {
        'reduce_dim': [SelectKBest(chi2)],
        'reduce_dim__k': N_FEATURES_OPTIONS,
        'classify__C': C_OPTIONS
    },
]
reducer_labels = ['PCA', 'NMF', 'KBest(chi2)']

grid = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid)
#X, y = load_digits(return_X_y=True)
df=pd.read_csv('nusrat_all_dataset.csv')

feature_set = list(df.columns.values) 
feature_set.remove('Class')
X=(df.drop(columns=['Class'])).values
Y=(df['Class'])

# drop rows with nan
Y=Y[~np.isnan(X).any(axis=1)]
X=X[~np.isnan(X).any(axis=1)]

X = MinMaxScaler().fit_transform(X)
y= np.zeros(Y.shape)
class_names=list(np.unique(Y))
class_num=0
number_of_classes=np.unique(Y).shape[0]
for classes in np.unique(Y):
    y[Y==classes]=int(class_num)
    print('Class '+ classes + ': ' + str(class_num))
    class_num=class_num+1


grid.fit(X, y)

mean_scores = np.array(grid.cv_results_['mean_test_score'])
# scores are in the order of param_grid iteration, which is alphabetical
mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))
# select score for best C
mean_scores = mean_scores.max(axis=0)
bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *
               (len(reducer_labels) + 1) + .5)

plt.figure()
COLORS = 'bgrcmyk'
for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):
    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])

plt.title("Comparing feature reduction techniques")
plt.xlabel('Reduced number of features')
plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)
plt.ylabel('Digit classification accuracy')
plt.ylim((0, 1))
plt.legend(loc='upper left')

plt.show()